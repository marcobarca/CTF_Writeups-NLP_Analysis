{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12d922d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3157b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = pd.read_csv('../writeups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45288638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Writeup_name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "      <th>Overview</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Attack_execution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XMarkTheSpot</td>\n",
       "      <td>web</td>\n",
       "      <td>Visiting the website, we are presented with a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XMarkTheSpot</td>\n",
       "      <td>web</td>\n",
       "      <td>The idea is similar to SQL injection. \\nWe hav...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XMarkTheSpot</td>\n",
       "      <td>web</td>\n",
       "      <td>For example, let's inject:\\nThis should tell u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Members</td>\n",
       "      <td>web</td>\n",
       "      <td>In the challenge members, we need to get more ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Members</td>\n",
       "      <td>web</td>\n",
       "      <td>If we leave the search query empty, we would s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Writeup_name Category                                               Text  \\\n",
       "0  XMarkTheSpot      web  Visiting the website, we are presented with a ...   \n",
       "1  XMarkTheSpot      web  The idea is similar to SQL injection. \\nWe hav...   \n",
       "2  XMarkTheSpot      web  For example, let's inject:\\nThis should tell u...   \n",
       "3       Members      web  In the challenge members, we need to get more ...   \n",
       "4       Members      web  If we leave the search query empty, we would s...   \n",
       "\n",
       "   Overview  Analysis  Attack_execution  \n",
       "0         1         0                 0  \n",
       "1         0         1                 0  \n",
       "2         0         0                 1  \n",
       "3         1         0                 0  \n",
       "4         0         1                 0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 5 rows of the csv\n",
    "npr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "268b8529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Visiting the website, we are presented with a login form (and a Robert Frost poem).\\nThe hint says \"XPATH\", and using some common XPATH injection techniques we can leak some information about the underlying DB.\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the first text\n",
    "npr['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "138315b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows of the dataset\n",
    "len(npr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb7b4c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<147x319 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2686 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# max_df = ignore high frequency terms (0-1)\n",
    "# min_df = ignore low frequency terms (min # of documents containing it)\n",
    "cv = CountVectorizer(max_df=0.9, min_df=4, stop_words='english')\n",
    "\n",
    "dtm = cv.fit_transform(npr['Text'])\n",
    "\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0b09e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=3, random_state=42)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# n_components is the number of topics we are looking for\n",
    "LDA = LatentDirichletAllocation(n_components=3, random_state=42)\n",
    "\n",
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55ffb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'command'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the vocabulary of words\n",
    "\n",
    "import random\n",
    "\n",
    "#len(cv.get_feature_names()) #589\n",
    "\n",
    "random_word_id = random.randint(0,779)\n",
    "\n",
    "cv.get_feature_names()[random_word_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dcd03d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "string\n",
      "challenge\n",
      "cookie\n",
      "function\n",
      "bypass\n",
      "code\n",
      "php\n",
      "flag\n",
      "file\n"
     ]
    }
   ],
   "source": [
    "# Grab the topics\n",
    "\n",
    "#len(LDA.components_) #3\n",
    "\n",
    "#type(LDA.components_) #numpy.ndarray - Contains the words and their probability\n",
    "\n",
    "# LDA.components_.shape # (3,589)\n",
    "\n",
    "single_topic = LDA.components_[0]\n",
    "\n",
    "single_topic.argsort() # returns an array containing the index position of each word instead of the word itself\n",
    "\n",
    "# ARGSORT ----> INDEX POSITION SORTED FROM LEAST TO GREATEST\n",
    "# TOP 10 VALUES (10 GREATEST VALUES)\n",
    "# LAST 10 VALUES of argsort()\n",
    "single_topic.argsort()[-10:] # grab the last 10 values of .argsort()\n",
    "\n",
    "top_ten_words = single_topic.argsort()[-10:]\n",
    "\n",
    "for index in top_ten_words:\n",
    "    print(cv.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "54da6d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['error', 'string', 'challenge', 'cookie', 'function', 'bypass', 'code', 'php', 'flag', 'file']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['login', 'javascript', 'code', 'using', 'script', 'password', 'use', 'page', 'website', 'flag']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['challenge', 'user', 'url', 'body', 'payload', 'request', 'array', 'value', 'code', 'admin']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grab the highest probability words per topic\n",
    "\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f\"THE TOP 15 WORDS FOR TOPIC #{i}\")\n",
    "    print([cv.get_feature_names()[index] for index in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f0fbcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Put in column the top\n",
    "topic_results = LDA.transform(dtm)\n",
    "\n",
    "npr['Topic'] = topic_results.argmax(axis=1)\n",
    "\n",
    "topic_dictionary = {0:'Topic 0',1:'Topic 1',2:'Topic 2'}\n",
    "\n",
    "npr['Topic Label'] = npr['Topic'].map(topic_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af62b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(npr)\n",
    "\n",
    "npr.to_csv(r'LDA_export_dataframe.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f2326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
